{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models\n",
    "\n",
    "In this chapter we will start with linear regression, We will discuss two different ways to train it,\n",
    "+ Using a direct \"closed-form\" equation that directly computes the model paramters that best fit the model to training set. (i.e. , the model parameters that minimize the cost function over the training set.)\n",
    "+ Using a iterative optimization approach, called Gradient Descent, that gradually tweaks the model parameters to minimize the cost function over the training set,eventually converging to the same set of parameters as the first method.\n",
    "\n",
    "Next we will look at Polynomial Regression, a more complex model that can fit nonlinear datasets.\n",
    "\n",
    "Finally we will look at two more models that are commonly used for classification, Logistic Regression and Softmax Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Vectorised form : y_hat = h_theta(X) = theta_transpose[1,n] * X[n,1].\n",
    "Training the model means setting the parameters(theta). For this we need a measure of how well (or poorly) the model fits the training data. RMSE or MSE can be minimized to find the best thetha.\n",
    "<!-- \\begin{equation*}\n",
    "\\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right)\n",
    "\\end{equation*} \n",
    "-->\n",
    "\n",
    "The Normal Equation\n",
    "theta_hat = (X_transpose * X)^-1 * (X_transpose) * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let us generate some linear looking data\n",
    "import numpy as np\n",
    "X = 2 * np.random.rand(100,1)\n",
    "y = 4 + 3*X + np.random.randn(100,1)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X,y,'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.87215759]\n",
      " [3.12934088]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XuYVNWd7vHvrxsaQbkoFy9gixceE7xjR6mWSCM2GmM0mUxOzGSMScwhGo0mY4wyjtGTxMHnmZOMmeO5DHFM4jM55mZmTs45yQlNS4uXBm0QQWK8IIIEIygqikDT3ev8saqo6qa7q7r2pXb1fj/Pw0P3rtuq3VVvrf1ba68y5xwiIjL81VS6ASIiEg8FvohISijwRURSQoEvIpISCnwRkZRQ4IuIpIQCX0QkJRT4IiIpocAXEUmJEXE+2KRJk9z06dPjfEgRkaq3evXqN5xzk4PeT6yBP336dDo6OuJ8SBGRqmdmm8O4H5V0RERSQoEvIpISCnwRkZRQ4IuIpIQCX0QkJRT4IiIpocAXEUkJBb6ISEoo8EVEUqJo4JvZ/Wa23cye7eeyb5iZM7NJ0TRPRETCUkoP/8fAxX03mtmxQDOwJeQ2iYhIBIoGvnNuBbCzn4v+Efgm4MJulIiIhK+sGr6ZXQb8yTn3TMjtERGRiAx5tUwzGwPcBiwo8foLgYUA9fX1Q304EREJSTk9/BOB44FnzOwVYBqwxsyO6u/KzrklzrkG51zD5MmBl3MWEZEyDbmH75xbD0zJ/Z4N/Qbn3BshtktEREJWyrTMB4F24GQz22pmV0ffLBERCVvRHr5z7jNFLp8eWmtERCQyOtNWRCQlFPgiIimhwBcRSQkFvohISijwRURSQoEvIpISCnwRkZRQ4IuIpIQCX0QkJRT4IiIpocAXEUkJBb6ISEoo8EVEUkKBLyKSEgp8EZGUUOCLiKSEAl9EJCUU+CIiKaHAFxFJCQW+iEhKFA18M7vfzLab2bMF2/7BzP5oZuvM7N/MbEK0zRQRkaBK6eH/GLi4z7YW4FTn3OnAC8CikNslIiIhKxr4zrkVwM4+25Y657qyv64EpkXQNhERCVEYNfwvAr8L4X5ERCRCgQLfzG4DuoCfDnKdhWbWYWYdO3bsCPJwIiISQNmBb2ZXAZcCn3XOuYGu55xb4pxrcM41TJ48udyHExGRgEaUcyMzuxi4BZjrnHs/3CaJiCRPezu0tUFTE2QylW5NeYoGvpk9CDQBk8xsK3AHflbOKKDFzABWOueuibCdIiIV094O8+dDZyfU1UFra3WGftHAd859pp/N/xJBW0REEqmtzYd9d7f/v62tOgNfZ9qKiBTR1OR79rW1/v+mpkq3qDxl1fBFRNIkk/FlnGFfwxcRiVqSBkQHaksmU/m2BaXAF5GKStKAaJLaEgXV8EWkovobEFVboqHAF5GKStKAaJLaEgWVdESkopI0IJqktkTBBlkVIXQNDQ2uo6MjtscTERkOzGy1c64h6P2opCMiUiHt7bB4sf8/DirpiIjEJDflc+JEePppuP9+P0Ac14wgBb6ISAxyUz737YOeHjCDXEU9ruUaVNIREYlBbspnT4//PRf2ZvHNCFLgi4jEIDflsyabujU1MGoUfPnL8Z3gpZKOiEgMCqd8TpwIb74Z/9RPBb6ISEwqvR6PSjoiIgHFPb2yXOrhi0jVSsIqm1EtuFb43MKiwBeRqpSUlS2j+Dasvs8Nxh4avKUq6YhIlUrKypZRLLjW97nBuLHB71U9fBGpUrmgzfWCK7WyZRQLrvV9bnv27Ho3+L2WsHiamd0PXApsd86dmt12BPBzYDrwCvAfnHNvFXswLZ4mImFKQg0/KoXPrbExnMXTSunh/xi4F3igYNutQKtz7m4zuzX7+y1BGyMiMhSVnuYYma4uMj2ryOxrgW+0hHa3RQPfObfCzKb32Xw50JT9+SdAGwp8EZHyOAcvvQQtLbB0KSxfDrt2+XUXGgJ37A8ot4Z/pHPuNd9O95qZTQmtRSIiabBzpy/+50J+82a/ffp0uOIKaG6GCy6AI47wwR+CyAdtzWwhsBCgvr4+6ocTEam4fscWOjv9BUuX+pDv6PA9+3Hj4IILaP/L79FGE01/cQSZxnACvq9yA/91Mzs627s/Gtg+0BWdc0uAJeAHbct8PBGRqpCfQ++oG+lo/fIvybz4ADzyCOze7edvzp4Nd9zhe/HnnEP7UyPy8+7/W3TnFJQb+L8BrgLuzv7/v0JrkYhItdq+nbZ7ttG55zS6qaWzu4u2H6wlM+NFuOoqWLDAd/vHj+91syhO3upP0cA3swfxA7STzGwrcAc+6H9hZlcDW4BPhd80EUm7xE+73LsXHnssX6ZZu5YmZlNHK/sYhdXUMPG7N8GixYPeTVznFOhLzEWkl6SEbFKWTujFOVi3Lj/Q+uijPvRHjoTGRt+Db25myepZXH9DLd3dfs37Uto+2H4P60vMdaatiByQpJCNq8xR1LZtPuBbWmDZMnj9db995kz/7SULFsD558Nhhx24yZvL/Ddb9fSU3vY4zilQ4ItUUFJ60zmJCVkquHTC7t2wYkW+TLNhg98+ebIfZM39mzp1wLtIyrIPfSnwRSokSb3pnCQFVRRr1PSrpwfWrMn34h9/3O+AUaPgwx/2g63NzXD66fnvJ0xK24dIgS9SIUnqTecMFlR9j0biODqJrMyxeXM+4Ftb/fcNApxxBtxwgy/TzJkDo0cXvauB9kMSl31Q4ItUSJJ604X6C6q+RyP33ANf+1rljk6G/GGza5e/QW6w9YUX/Pajj4ZLL/U9+AsvhCOPHHI7knaUNhgFvkiFJPWwvz99j0Yeeijco5OhBHhJIdvVBU89le/Fr1zpt40ZA3PnwjXX+F78zJmBli1I4lHaYBT4IhWUxMP+/vQ9GvnkJ/2MxDCOTobaSx4wZDduzA+0PvwwvPOOD/Ozz4abb/a9+MZGX5sPSVKP0gaiwBeRovo7GjnttHCOTobaS86HrKOutpumVd+DE/4ZNm3yV6ivh099ygf8/PkwcSKQPYr4frhHU9V0lAY68UpEKqzkHn5npy/NtLTQ/uvXaHtuCk1uOZmxG2DevAMnPTFjxkFlmmqrtfelE69EJFZRzcoZsJfsHDz/PO1L1tP2u/dp2vwAmT0PQ00NmXPPJXP7VGj+Bzj3XH+m6yCKHUUk7XyIqCjwRaSosHrIRacwvvEG/GzZgdk07VunMZ9WOqmjbsRnaF3cTuaaM2DChCE97mC19mrv/Q+FAl9EigpjNkq/wTprnz/RKTfY+vTTvmc/YQLMn09bw810/mY03T1Gp4M2N5fM0LIeGLzWXm0zbYJQ4ItIUWHMRvHB6ujuNjr39tB21U/IbL0O9uyBESN8yn7729DcTPv+BtoerWXiRKj7fTizYAaaEZXUmTaFR0NhUeCLSFED9ZBLqn3/+c/Q0kLTik3Udd9MJyOoc/tp6lwKX/qSH2ydOxfGjgVgyRK4/noOrDR5zz3+RNio6utJnGnT92gIxh4axv0q8EWkJH17yAPWvt9/30/Sz5Vp1q/3t584kdYLu2gbdxlNVx5L5uMPHvQY7e1w3XX+HCmAfft82C9aFO9zq7S+ZSYYNzaM+1Xgi6RE2DNReoeSo+0/rSCz/9v+C0FynwJz5sDdd/vpkmeeSaamhsEeuq3Nr2WWU1ubnBJLnPqWmfbs2fVuGPerwBdJgdBnorz6Kk3vrqWOBXRSQ133fpp+fyucttvXYxYs8CtNjhkzpLttavJlnH37/MKU996bnJ53nFM3+5aZGhvf3R3G/SrwRVIg8EyUd9/1X8KdW3zsj38EZnPV6J0wbRqfu6KTzLW/9ouRBdBfPT0Jc+QrMXUzijKTAl8kBYY8E6W7Gzo68ouPPfGEL6yPHg3nn09787eY/8NP09lp1G01PvcRIFjWH1AYdEmZIz9cpm4q8EUSIsqebEkzUTZt6r342Ftv+e2zZsFNN/kyTWMjHHIIbYuhc3/vAITw25+UoE3q1M2hChT4ZvZ14EuAA9YDX3DO7Q2jYSLVJkhgx9GTPahE8PbbsHx5vkyzcaPfPm0afOIT+cXHJk8+6L76BuDEidG0P4qgLefvlMSpm+UoO/DNbCpwAzDTObfHzH4BXAH8OKS2iVSF9nZ44AH40Y9g/34/s+Tee2HhwtLvI5ae7P79sGpVvkyzapWfEnPYYT7FbrzRh/zJJxddI75vAEbV/rCDNsgHa9KmbpYjaElnBDDazPYDY4BtwZskUj1yAbJ3r18RAHyGXnedXz641ICIpGTgHLz4Yr5Ms3y5H3ytqYEPfQj+9m99wM+enTu7Z0j6BmBUJY8wgzYpJaJKKTvwnXN/MrP/DGwB9gBLnXNLQ2uZSBXIBUjfVcZ7eoZW1w6tJ/vmm/6OcmWaLVv89uOPh7/6Kx/wF1wAhx9e5gP0L4qeeBTlk+FSiy9X2evhm9nhwEPAp4G3gV8Cv3LO/Wuf6y0EFgLU19efvXnz5kANFkmSwhKBmQ9+5/JLAkT+va/79vlG5Hrxq1f7Bowf74M9t0b8iSeG/MDRiXo8IwnTPIcqCevhXwhscs7tyDbo10Aj0CvwnXNLgCXgvwAlwOOJJE7fni1EXNd2jvb/uYm2B1+j6c2HyKz7Z7+UQW2tv/M77/QB/6EP+QXJIhJlaEZddhkOtfhyBXlFbAFmm9kYfElnPqCvs5Jhq+ha7gW/59TW+vJOoCUCXn8dlvk14pf8+2Sue+cueqhnlM2i9S+mkvncDH/n48aV+QBDE3UPPO1llygFqeGvMrNfAWuALuBpsj15keGm3JDLTXYpMumltz17/Ho0uTLNM8/4NoxdwPXv3UcXtYCxz0bQdvZNZC4b8tMJJI4e+HCYAplEgY75nHN3AHeE1BaRxCon5Nra/Mmpzvn/H3hggBDr6YF16/IDrY8+6mvzI0fCeefB3/89NDfT9vtZdH+rxp/1gp9sU4nebxw98DSXXaKkM21FSlBOyBXeZsQIuP9+/4FRVwetP9tBZuf/zc+J37HD3+iUU2i//G7aRn+Eps/Vk7lgdP7+9sOou/xnQW6ufyVCUT3w6lX2LJ1yNDQ0uI4OlfmlOpUzUJm7zZaN+/nhj2rp7qmhli6+w+0s4m6YMsUPsjY3w4UX0r5l6qClo2qcYSLBJWGWjkiqDKnM0N0Na9aQWd5CZulS2h/r5ic9v6eTkdTVdNN07anwH9f6s7Nqag7crO2BwUtHKnVIEAp8kbBs3pwfaG1thZ07/fYzzyTzN820TttA29tn0tR8CJnMZ/u9C81QkSgp8KVfKh2UYNeu3ouPvfii337MMXDZZQfKNEyZAkAm+28wqo9LlBT4cpBKrEFeFR8wXV3w5JP5gdaVK33tZcwY3/DrrvMh/8EPDnEeZm8q20hUFPhykLgXmIr7A6bkDxfn/JLBhWvE79rlw7yhAW65xS9dkMmUtfiYSNwU+HKQuOvIcX7AFP1w2bnTB3uuTPPKK377ccfBpz+dX3xs4sRoGlhlquLITA5Q4MtBitWRw36Tx/kBc9CHS2sXmc7H82Wajg5/ItS4cTBvHtx8sw/5k04KVKYZjpLy9YNSOgW+9GugOnIUb/I4Byqb5jrqRjo6HdS5/TTd9RHYu9yfyXTuuXD77T7gzznHn+kqA0r72vLVSIE/jMRxeB32m7ywzYsWhdPGg+zYcWDxsczSpbTuPZY2mmia+hKZyz8IzTf43vz48RE1YHjSFNLqo8AfJuI6vA7zTR5Zm/fuhccfzw+2Pv2033744TB/PpkFC8g0N8P06SE8WHppCmn1UeAPE2H1vIsdJYT5Jg/taME5WL8+P9C6YoUP/ZEjobERvvtdX6Y5+2xfuimi1COl4TpgOZTnpSmk1UWBH4IkvPHD6HmX2uMO600eqM2vvZYfaG1p8WvGg58D/+Uv+4CfO9d/QfcQlLoPqmHAsty1f5L+vKR8CvyAkvIGCaPnHfcg3JDa/P77vueeK9M8+6zfPnmyP5s1twDZtGmB2lTqPkj6gGW5r8ukPy8JRoEfUJLeIEF73pUYhBuwzT09vvaeK9M8/rhv2KhRMGcOXHmlD/gzzui1+FhQpe6DpA9Ylvu6TPrzkmAU+AEl7Q0SpLxU8UG4LVvyJZply+DNN/3200+Hr37Vn9U6Z45fyiAipe6Diu+rIsp9XYb5vJJQ6pTetB5+CJLywk5Kealk777rd1yuTPP88377UUf5cM8tPnbUURVtZrWq5Ouy6l6LCaf18BMkKTMVoiwvhRIeXV3+TNZcmWblSr9t9Gg/wJobbD3lFJ3VGoJKvi6TVOqUPAV+BUTV84qqvBSot/byy70XH3v7bR/ms2bBN77he/KNjb42H6B9STjCkryklTrFCxT4ZjYBuA84Ff/Vyl90zrWH0bAkCTNQojzUjaquPKTe2ttv91587OWXAWifcjltJ91H02XjyVx7JkyaFErbVDpIpqSPcaRV0B7+D4D/55z7SzOrA6IbTauQsAMl6kPdKA7jB+2t7d/vSzO5wdYnn/QzbA47zC9X8PWv0z7pY8z/Yj2dTxt1G6D1QsiUkff9ffCqdJBcSSl1Sl7ZgW9m44Dzgc8DOOc6gc5wmpUcYQdKNR7q9uqtzXVkjngB/ku2TNPW5gdfa2r8gmO33ebr8LNnH1h8rG1x8H040AdvNe5PkUoJ0sM/AdgB/MjMzgBWAzc653aH0rKECDtQqvJQ9403yGxpJbOxBf77Unj1Vb/9hBPgs5/1AT9vnl+rph9h7MOBPnircn+KVEjZ0zLNrAFYCZznnFtlZj8Adjnnbu9zvYXAQoD6+vqzN2/eHLDJ8Qtaw6+6QcV9+/yJTrkyzZo1fr2aCRP8l3/kpkyecELJdxnGPlStXtIqrGmZQQL/KGClc2569vcPA7c65z460G2G6zz8wVRFUDkHGzbkZ9OsWOGXMhgxwjc2t2xBQ4PfViFV98EpEpKKz8N3zv3ZzF41s5Odc88D84E/BG3QcJPYQcU///nAGvG0tPjFyABOPhmuvtoHfFMTjB0b+KHCCmoNAooEE7S79lXgp9kZOi8DXwjepOElMYOKe/bAo4/me/Hr1vntEyf2Xnysvj7Uh62KIxyRlAgU+M65tUDgw4zhrGKDij098Mwz+fnwjz3ma/N1dX49msWLfcCfddaAi4+F0TNP7BGOSArpTNsYxFaK2Lq19+JjO3b47aeeCl/5ih9s/fCH4dBDi95VWD3zxBzhiEhyAl8DcmV47z145JF8mea55/z2I4+Eiy7KLz52zDEH3bTY/g6rZ65pkyLJkYjAV523RN3dsHp1vkzT3u7PdD3kEDj//Pxg62mnDbr4WCn7O8yeuQZbRZIhEYFfqTpvko4qBmzLK6/ke/CtrfDWW377WWfB17/uyzTnnedDv0Sl7O9q7Jkn6e8pkkSJCPxK1HmTdFTRuy2O1m+tILPl5z7kX3rJX2nqVPj4x30Pfv58mDKl7McrdX/H2TPXiVki0UtE4FeiN5mY2SP799P2kz/RubeeblfDvj3d3LloD3ce8kcy80/23/TU3Awf+EBoa8QnrfceRlgn5u8pkmCJCHzo3ZuM49C8YrNHnPO99lyZZvlymnbNpI5W9lFHD7Uss4t41C6i9Tbr9/mHsX+SVFcvN6wL94NmA4kUl5jAzym1txc09GLt5e7c6R8sF/K59YSmT4crriDT3Ezr2C7u/P4Yli3zU+gHCr7hWLooJ6z72w9JOmoRSaLEBX4pvb2wQi+yXm5nJzzxRH5OfEeH79mPG+cXH7vlFl+mOfHEA2WaDHDnOH8y7GDBNxxLF+V8+Pa3HxYtqv59IRKlxAV+Kb29xIWec34OfK4H/8gjsHs31Nb6deHvuMMH/DnnDLr4WCnBN1xLFwN9+A50JDdc98NgNAtJgip7tcxylLpaZrEXdiLKGtu35xcfW7oUtm3z22fMyC8f3NQE48eH/tBpeeMX+zuXsh+Gy75KxGteKqbiq2VGqVippZSecOhv9D17/Ho0uTLN2rV++xFH+HdiLuSPOy6EBxtckgZcw9T3b1bsSK7YfhhOIZm4o1qpSokM/FIM9mYP5Y3e0wPr1+d78I8+Cnv3+q/tO+88uOsuH/CzZvnSjQTS398saNlmOIVkGktYEr6qCPz+euuD9eDLfqNv25bvwbe0+LINwMyZcM01PuDPP99/QXeVS1qpY6BB2CAzb4ZTSCbt3AmpTokP/P56fjB4D77kN/ru3f7bnXKDrRs2+O1TpvReI37q1AifYfySWOoY6G8WpHw13EJyuJbyJD6JD/z+en5QvLbb7xu9uxuefjpfpnniCX8Ho0b5nvtVV/mAP/30AdeIL0c19KYr3a6owlkhKZKX+MAfqOdXrAd/4I2+eTPcV7BG/M6d/gpnnAE33OAHW+fMgdGjI2l/WL3pMD80klrqUDiLRKvigV8syAbq+Q3YG9y1y1+QK9O88ILffswx8LGP5deIP/LI6J5UgTB602GXYIZbqUNESlPRwC81yPrr+R3Y1tUF7U/lyzQrV/p0HTMG5s6Fa6/1IT9zZmiLjw1FGL3pKEow6k2LpE9FA7/sINu4Md+Df/hheOcdH+Znnw3f/KYv02QyvjZfYWH0ppNaghGR6hI48M2sFugA/uScu3Qoty05yN56ywd7LuQ3bfLb6+vhU5/KrxE/cWKAZxKdoL1plWBEJAxh9PBvBJ4Dxg31hgMGWWenL83k5sM/9ZQ/EWrsWJg3D266yYf8jBkVKdNUgkowIhJUoMA3s2nAR4G7gL8p5z4yGcjMdvD88/BP2R58W5v/gu6aGjj3XPi7v/NlmnPO8We6iojIkAXt4d8DfBMYO+Rb7tjRe434rVv99hNPhCuv9D34efNgwoSDbpq0ee0iItWg7MA3s0uB7c651WbWNMj1FgILAU6aMgVuvdUH/Jo1/goTJvj6++23+5A//vhBHzeJZ4mKiFSDID3884DLzOwS4BBgnJn9q3Purwuv5JxbAiwBaDBzfO970NgI3/mOD/iGhiEtPpbEs0RFRKpB2YHvnFsELALI9vC/0TfsD3LSSb5nP3boFaCcsKcoqjwkImkR7zz88eMDhT2EO0VR5SERSZNQAt851wa0hXFfpQhriqLKQyKSJuEtCVmFcuWh2lqdwSoiw1/FF0+rJJ3BKiJpUpHAT9JAqc5gFZG0iD3wNVAqIlIZsdfwB/oGq8G0t8Pixf5/EREpT+w9/KHOo4/7iCBJ5SYRkTDFHvhDHSiNc+pk0stN+jASkSAqMmg7lIHSOL/8I8nz8pP+YSQiyZf4aZlxTp1M8jdLJfnDSESqQ+IDH+KbOpnkeflJ/jASkepQFYEfp6TOy0/yh5GIVAcFfhVJ6oeRiFSHVK+lIyKSJgp8EZGUUOCLiKSEAl9EJCUU+CIiKaHAFxFJCQW+iEhKKPBFRFKi7MA3s2PNbLmZPWdmG8zsxjAbJiIi4Qpypm0XcJNzbo2ZjQVWm1mLc+4PIbVNRERCVHYP3zn3mnNuTfbnd4HngKlhNUxERMIVSg3fzKYDZwGrwrg/EREJX+DAN7PDgIeArznndvVz+UIz6zCzjh07dgR9OBERKVOgwDezkfiw/6lz7tf9Xcc5t8Q51+Cca5g8eXKQhxMRkQCCzNIx4F+A55xz3w+vSSIiEoUgPfzzgCuBC8xsbfbfJSG1S0REQlb2tEzn3GOAhdgWERGJkM60FRFJCQW+iEhKKPBFRFJCgS8ikhIKfBGRlFDgi4ikhAJfRCQlFPgiIimhwBcRSQkFvohISijwRURSQoEvIpISCnwRkZRQ4IuIpIQCX0QkJRT4IiIpocAXEUkJBb6ISEoo8EVEUkKBLyKSEoEC38wuNrPnzewlM7s1rEaJiEj4yg58M6sF/ivwEWAm8BkzmxlWw0REJFxBevjnAC855152znUCPwMuD6dZIiIStiCBPxV4teD3rdltIiKSQCMC3Nb62eYOupLZQmBh9td9ZvZsgMeMyyTgjUo3ogRqZ3iqoY2gdoatWtp5chh3EiTwtwLHFvw+DdjW90rOuSXAEgAz63DONQR4zFioneGqhnZWQxtB7QxbNbUzjPsJUtJ5CphhZsebWR1wBfCbMBolIiLhK7uH75zrMrPrgd8DtcD9zrkNobVMRERCFaSkg3Put8Bvh3CTJUEeL0ZqZ7iqoZ3V0EZQO8OWqnaacweNs4qIyDCkpRVERFIitMAvtsyCmY0ys59nL19lZtMLLluU3f68mV0UVpvKaOPfmNkfzGydmbWa2XEFl3Wb2drsv0gHp0to5+fNbEdBe75UcNlVZvZi9t9VFW7nPxa08QUze7vgslj2p5ndb2bbB5oObN4/ZZ/DOjObVXBZnPuyWDs/m23fOjN7wszOKLjsFTNbn92XoczmCNDOJjN7p+Bv+62Cy2JbiqWEdt5c0MZns6/HI7KXxbI/zexYM1tuZs+Z2QYzu7Gf64T7+nTOBf6HH7TdCJwA1AHPADP7XOcrwP/I/nwF8PPszzOz1x8FHJ+9n9ow2lVGG+cBY7I/X5trY/b398JuU4B2fh64t5/bHgG8nP3/8OzPh1eqnX2u/1X8wH7c+/N8YBbw7ACXXwL8Dn9eyWxgVdz7ssR2NuYeH7+cyaqCy14BJiVkfzYB/yfo6yXqdva57seAh+Pen8DRwKzsz2OBF/p5r4f6+gyrh1/KMguXAz/J/vwrYL6ZWXb7z5xz+5xzm4CXsvcXtqJtdM4td869n/11Jf7cgrgFWbLiIqDFObfTOfcW0AJcnJB2fgZ4MKK2DMg5twLYOchVLgcecN5KYIKZHU28+7JoO51zT2TbAZV7bZayPwcS61IsQ2xnpV6brznn1mR/fhd4joNXKwj19RlW4JeyzMKB6zjnuoB3gIkl3jauNha6Gv/JmnOImXWY2Uoz+3gE7csptZ2fzB7i/crMcifAxbncRcmPlS2NHQ88XLA5rv1ZzEDPI8lLh/R9bTpgqZmtNn9me6VlzOwZM/udmZ2S3ZbI/WlmY/BB+VDB5tj3p/kS91nAqj4Xhfr6DDQts0ApyywMdJ2SlmgIQcmPY2Z/DTQAcws21zvntpnZCcDDZrbeObexQu3838CDzrl9ZnYN/sjpghJvG5ahPNZLvHdwAAACeUlEQVQVwK+cc90F2+Lan8VU+nU5JGY2Dx/4cwo2n5fdl1OAFjP7Y7aHWwlrgOOcc++Z2SXAvwMzSOj+xJdzHnfOFR4NxLo/zeww/AfO15xzu/pe3M9Nyn59htXDL2WZhQPXMbMRwHj8IVdJSzTE1EbM7ELgNuAy59y+3Hbn3Lbs/y8DbfhP4ygUbadz7s2Ctv0QOLvU28bZzgJX0OeQOcb9WcxAzyPOfVkSMzsduA+43Dn3Zm57wb7cDvwb0ZRES+Kc2+Wcey/782+BkWY2iQTuz6zBXpuR708zG4kP+586537dz1XCfX2GNPgwAj9ocDz5AZlT+lznOnoP2v4i+/Mp9B60fZloBm1LaeNZ+IGlGX22Hw6Myv48CXiRiAacSmzn0QU/fwJY6fIDOZuy7T08+/MRlWpn9non4wfBrBL7M/sY0xl4kPGj9B4UezLufVliO+vx41uNfbYfCowt+PkJ4OIKtvOo3N8aH5Rbsvu2pNdLXO3MXp7rdB5aif2Z3S8PAPcMcp1QX59hNv4S/CjzRuC27LZv43vKAIcAv8y+aJ8ETii47W3Z2z0PfCTCF0CxNi4DXgfWZv/9Jru9EViffZGuB66O+IVarJ2LgQ3Z9iwHPlBw2y9m9/FLwBcq2c7s73cCd/e5XWz7E997ew3Yj+8VXQ1cA1yTvdzwX+SzMduWhgrty2LtvA94q+C12ZHdfkJ2Pz6TfU3cVuF2Xl/w2lxJwQdUf6+XSrUze53P4yeMFN4utv2JL8s5YF3B3/WSKF+fOtNWRCQldKatiEhKKPBFRFJCgS8ikhIKfBGRlFDgi4ikhAJfRCQlFPgiIimhwBcRSYn/Dy8Ud7Jp10hPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the Normal equation finding theta_hat\n",
    "X_b = np.c_[np.ones((100, 1)), X] # add x0 = 1 to each instance\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "# Function generated was y = 4 + 3X + White Noise.\n",
    "# theta_best : [4.23524939], [2.8365066 ]\n",
    "print(theta_best)\n",
    "\n",
    "# In order to make predicts now,\n",
    "X_new = np.array([[0],[2]])\n",
    "X_new_b = np.c_[np.ones((2,1)), X_new] # add x0 = 1 to each instance\n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "y_predict\n",
    "\n",
    "plt.plot(X_new, y_predict, \"r-\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.87215759],\n",
       "       [10.13083934]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent sci-kit learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "lin_reg.intercept_, lin_reg.coef_\n",
    "lin_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Complexity\n",
    "The normal equation computes the inverse of X_transpose * X which is an n X n matrix (n number of features). The computational complexity of inverting such a matrix is O(n^2.4) to O(n^3). If you double the number of features the training time increases 8 times.\n",
    "On the positive side, this equation is linear with regards to the number of instances in the training set (it is O(m)), so it handles large data efficiently provided it has sufficient memory.\n",
    "After training is done predictions are faster.\n",
    "\n",
    "Now we will look at very different ways to train a Linear Regression model, better suited for cases\n",
    "where there are a large number of features, or too many training instances to fit in memory.\n",
    "\n",
    "### Gradient Descent\n",
    "Gradient descent is a very generic optimization problem to a wide range of problems. The idea is to tweak the parameters iteratively till you minimize the cost function. It measures the local gradient of the error function with regards to the parameter vector θ, and it goes in the direction of descending gradient. Once the gradient is zero, you have reached a minimum!\n",
    "\n",
    "You start by filing θ with random values (this is called random initialization), and then you improve it gradually, taking one baby step at a time, each step attempting to decrease the cost function (e.g the MSE), until the algorithm converges to a minimum.\n",
    "\n",
    "![](GD_start.png)\n",
    "\n",
    "An important parameter in Gradient Descent is the size of the steps, determined by the learning rate hyperparameter. If the learning rate is too small, then the algorithm will have to go through many iterations to converge, which will take a long time\n",
    "\n",
    "![](GD_slow.png)\n",
    "\n",
    "On the other hand, if the learning rate is too high, you might jump across the valley and end up on the other side, possibly even higher up than you were before. This might make the algorithm diverge, with larger and larger values, failing to find a good solution\n",
    "\n",
    "![](GD_fast.png)\n",
    "\n",
    "Finally, not all cost functions look like nice regular bowls. There may be holes, ridges, plateaus, and all\n",
    "sorts of irregular terrains, making convergence to the minimum very difficult. Two main challenges with Gradient Descent: if the random initialization starts the algorithm on the left, then it will converge to a local minimum, which is not as good as the global minimum. If it starts on the right, then it will take a very long time to cross the plateau, and if you stop too early you will never reach the global minimum.\n",
    "\n",
    "![](GD_fast.png)\n",
    "\n",
    "Fortunately, the MSE cost function for a Linear Regression model happens to be a convex function, which\n",
    "means that if you pick any two points on the curve, the line segment joining them never crosses the curve.\n",
    "This implies that there are no local minima, just one global minimum. It is also a continuous function with\n",
    "a slope that never changes abruptly. These two facts have a great consequence: Gradient Descent is\n",
    "guaranteed to approach arbitrarily close the global minimum (if you wait long enough and if the learning\n",
    "rate is not too high).\n",
    "In fact, the cost function has the shape of a bowl, but it can be an elongated bowl if the features have very\n",
    "different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.80599604],\n",
       "       [3.18263092]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementation of Batch gradient descent implementation.\n",
    "X_b = np.c_[np.ones((100, 1)), X]\n",
    "eta = 0.1\n",
    "n_iterations = 100\n",
    "m = 100\n",
    "\n",
    "theta = np.random.randn(2,1) # random initialisation.\n",
    "# print(theta)\n",
    "\n",
    "# print(float(2)/m)\n",
    "# print(X_b.T.dot(X_b.dot(theta) - y))\n",
    "\n",
    "for iterations in range(n_iterations):\n",
    "    gradients = (float(2)/m) * (X_b.T.dot(X_b.dot(theta) - y))\n",
    "    #     print(gradients)\n",
    "    theta = theta - (eta * gradients)\n",
    "    \n",
    "theta\n",
    "# Doesnt converge for me. dont know what is problem.\n",
    "# Resolution 2/m was giving out zero. float(2)/m gave proper result now gradients get non-zero values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "+ Main problem with batch gradient descent is that it used the whole trainig set to compute the gradients at ever step, which makes it very slow when the training set is huge.\n",
    "+ At the opposite end *Stochastic Gradient Descent* just picks a random instance in the training set at every steps and computes the gradients based only on that single instance.\n",
    "    * This makes it faster\n",
    "    * Only one instance needs to be in memory.\n",
    "+ On other hand, due to stochastic (random) nature, this algo is less regular than Batch Gradient Descent. Instead of gently reaching the minimum, it will bounce up and down, decreasing only on average. Over time it will end up very close to the minimum, but once it reaches it will continue to bounce.\n",
    "    * Once the alogrithm stops, the parameters will be good, but not optimal.\n",
    "    * When the cost function is irregular SGD can help to jump out of a local minima, hence it has more chances of reaching global minima than Batch Gradient.\n",
    "    \n",
    "![](SGD_1.png)\n",
    "\n",
    "Therefore randomness is good to escape from local optima, but bad because it means that the algorithm can never settle at the minimum. One solution to this dilemma is to gradually reduce the learning rate. The steps start out large (which helps make quick progress and escape local minima), then get smaller and smaller, allowing the algorithm to settle at the global minimum. This process is called simulated annealing, because it resembles the process of annealing in metallurgy where molten metal is slowly cooled down. The function that determines the learning rate at each iteration is called the learning schedule. If the learning rate is reduced too quickly, you may get stuck in a local minimum, or even end up frozen halfway to the minimum. If the learning rate is reduced too slowly, you may jump around the minimum for a long time and end up with a suboptimal solution if you halt training too early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.81199569],\n",
       "       [3.15716273]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "t0, t1 = 5, 50 # learning schedule hyperparameters\n",
    "def learning_schedule(t):\n",
    "    return float(t0) / (t + t1)\n",
    "\n",
    "theta = np.random.randn(2,1) # random initialization\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        eta = learning_schedule(epoch * m + i)\n",
    "        theta = theta - eta * gradients\n",
    "        \n",
    "\n",
    "# By convention we iterate by rounds of m iterations; each round is called an epoch. While the Batch\n",
    "# Gradient Descent code iterated 1,000 times through the whole training set, this code goes through the\n",
    "# training set only 50 times and reaches a fairly good solution:        \n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishant.wankhede\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3.84166451]), array([3.10437888]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(n_iter=50, penalty=None, eta0=0.1)\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
